# 設計レベルメモ（タスク分解＆実験設計）

**Date**: 2026年1月15日  
**Project**: 少量音素コーパスを用いた日本語TTS構築実験  
**Version**: 1.0

---

## 1. プロジェクト全体概要

### 1.1 研究目的
音素カバレッジとコーパス設計（4文 vs 80文など）が、fine-tuningされた日本語TTSモデルの出力品質に与える影響を、客観指標（MCD, log-F0 RMSE, CER）を用いて明らかにする。

### 1.2 実験条件（4条件）
| 条件ID | 条件名 | 文数 | 特徴 |
|--------|--------|------|------|
| E1 | 80文コーパス | 80 | データ量最大、分布的にバランス良い |
| E2 | 37音素4文 | 4 | 音素カバレッジ最大、データ量最小 |
| E3 | ランダム4文 | 4 | カバレッジ・分布ともに無作為（対照群） |
| E4 | 上位10文 | 10 | 音素特徴量上位10文（情報量重視） |

### 1.3 全体スケジュール（7日間）
- **1/15-1/16 (2日)**: 環境構築・データ準備
- **1/17-1/19 (3日)**: Fine-tuning実験
- **1/20-1/21 (2日)**: 評価・分析
- **1/22 (1日)**: ドキュメント整備

### 1.4 評価指標
- **MCD (dB)**: スペクトル類似度（低いほど良い）
- **log-F0 RMSE**: ピッチ輪郭の誤差（低いほど良い）
- **CER**: 文字エラー率（低いほど良い）

---

## 2. 各テーマセクション

### [Phase 1] 環境構築・データ準備

#### 目的
ESPnet2/StyleTTS2の選定と環境構築を完了し、JVS parallel100データを取得・確認できる状態にする。

#### 前提
- **OS**: WSL2 Ubuntu 24.04
- **GPU**: RTX 4070 Ti (12GB VRAM)
- **Python**: 3.12.9（既存venv環境 `/home/gohan/.venv` を使用）
- **データ**: JVS parallel100 - jvs002話者（100文）をダウンロード可能
- **既存インストール済み**: PyTorch 2.5.1+cu121, CUDA関連パッケージ（nvidia-*）、GPU認識済み
- **追加必要**: ESPnet2/StyleTTS2, pyopenjtalk, librosa, soundfile等のTTS関連パッケージ

#### タスク
- [x] ESPnet2とStyleTTS2の比較調査（公式ドキュメント、日本語対応状況、評価スクリプトの有無）
- [x] TTS基盤の選定決定（ESPnet2優先、失敗時はStyleTTS2）
- [x] 既存venv環境の確認と有効化（`/home/gohan/.venv`）
- [x] PyTorch動作確認（CUDA認識、GPU利用確認）
- [x] requirements.txtの作成（TTS関連パッケージのみ記載）
- [ ] ESPnet2のインストール（またはStyleTTS2）
- [x] 依存ライブラリのインストール（pyopenjtalk, librosa, soundfile, matplotlib, seaborn等）
- [ ] JVS parallel100データのダウンロード・配置確認
- [ ] jvs002話者の100文データの存在確認（音声ファイル、テキストファイル）
- [ ] 簡単な動作テスト（ESPnet2のサンプル実行またはStyleTTS2のデモ実行）

#### 完了条件
- 既存venv環境が正常に有効化され、PyTorchがGPU認識していることを確認済み
- ESPnet2（またはStyleTTS2）が正常にインストールされ、インポート可能
- JVS parallel100のjvs002話者データが`data/jvs002/`に配置されている
- GPUが認識され、簡単な推論が実行できる
- requirements.txtに全依存関係が記載されている（PyTorch等の既存パッケージは除外）

---

### [Phase 2] 音素分析・コーパス選定

#### 目的
100文から37音素インベントリを抽出し、4条件のコーパス（80文/37音素4文/ランダム4文/上位10文）の文IDリストを生成する。

#### 前提
- **入力**: JVS parallel100 jvs002話者の100文テキスト
- **音素解析**: pyopenjtalkで音素列を取得
- **既知情報**: 貪欲法により「4文で37音素を全てカバーする組」が存在することを確認済み
- **出力形式**: JSON/CSVで音素分布と文IDリストを保存

#### タスク
- [x] `src/phoneme_analysis.py`の作成（音素ラベル抽出スクリプト）
- [ ] pyopenjtalkを使用した100文の音素列抽出（JVSデータ準備後に実行）
- [ ] 37音素インベントリの確認・リスト化（JVSデータ準備後に実行）
- [ ] 各文の音素分布（ユニーク音素数、頻度）を計算（JVSデータ準備後に実行）
- [ ] 音素分布データをJSON/CSV形式で保存（`results/phoneme_distribution.json`）（JVSデータ準備後に実行）
- [x] `src/corpus_selection.py`の作成（コーパス選定スクリプト）
- [ ] 80文コーパスの選定（8:2分割、ランダムシード固定）（JVSデータ準備後に実行）
- [ ] 37音素カバー4文の選定（貪欲法、既存結果の再現または新規計算）（JVSデータ準備後に実行）
- [ ] ランダム4文の選定（シード固定、含有音素数を計測）（JVSデータ準備後に実行）
- [ ] 上位10文の選定（音素特徴量スコアリング: ユニーク音素数 + レア音素数）（JVSデータ準備後に実行）
- [ ] 4条件の文IDリストをJSON形式で保存（`results/corpus_selection.json`）（JVSデータ準備後に実行）
- [ ] 各条件の音素カバレッジを確認・記録（JVSデータ準備後に実行）
- [ ] テストセットの確定（4条件すべてで未学習となる10-20文）（JVSデータ準備後に実行）

#### 完了条件
- `results/phoneme_distribution.json`に100文の音素分布が保存されている
- `results/corpus_selection.json`に4条件の文IDリストが保存されている
- 各条件の音素カバレッジが確認でき、37音素4文は全37音素をカバーしている
- テストセット（10-20文）が確定している

---

### [Phase 3] データ前処理

#### 目的
JVS parallel100データをESPnet2（またはStyleTTS2）の学習形式に変換し、4条件それぞれの学習用データセットを準備する。

#### 前提
- **入力**: JVS parallel100 jvs002話者の音声ファイル（WAV）とテキストファイル
- **出力形式**: ESPnet2の`data.list`形式（またはStyleTTS2の形式）
- **データ分割**: 各条件で学習用/テスト用に分割（テストセットは共通）
- **前処理**: 音声の正規化、テキストの音素変換

#### タスク
- [ ] `src/preprocess.py`の作成（データ前処理スクリプト）
- [ ] JVSデータの読み込み（音声ファイル、テキストファイルのパス取得）
- [ ] 音声ファイルの確認（サンプリングレート、チャンネル数、長さ）
- [ ] テキストから音素列への変換（pyopenjtalk使用）
- [ ] ESPnet2形式の`data.list`生成（音声パス、音素列、話者ID）
- [ ] 4条件それぞれの学習用データリスト生成
- [ ] テストセットのデータリスト生成（共通）
- [ ] データディレクトリ構造の作成（`data/train_80sent/`, `data/train_4sent_37phonemes/`等）
- [ ] 前処理済みデータの保存先確認
- [ ] データ整合性チェック（ファイル存在確認、音素列の妥当性）
- [ ] 前処理ログの出力（処理した文数、エラー文の有無）

#### 完了条件
- 4条件それぞれの学習用データリスト（`data.list`形式）が生成されている
- テストセットのデータリストが生成されている
- すべての音声ファイルと音素列が正しく対応している
- データディレクトリ構造が整備されている

---

### [Phase 4] Fine-tuning実験（4条件）

#### 目的
事前学習済み日本語TTSモデルを各条件のコーパスでfine-tuningし、チェックポイントを保存する。

#### 前提
- **ベースモデル**: ESPnet2の事前学習済み日本語TTSモデル（またはStyleTTS2）
- **学習条件**:
  - 80文: 5k-10k steps
  - 4文/10文: 1k-3k steps
- **GPU**: RTX 4070 Ti (12GB VRAM)
- **バッチサイズ**: GPUメモリに応じて調整
- **学習率**: ベースライン実装の推奨値を基本踏襲

#### タスク
- [ ] `src/train.py`の作成（fine-tuningスクリプト）
- [ ] ESPnet2設定ファイル（YAML）の作成（またはStyleTTS2設定）
- [ ] 事前学習モデルのダウンロード・配置確認
- [ ] 学習スクリプトの実装（チェックポイント保存、ログ出力）
- [ ] 乱数シード固定の実装
- [ ] バッチサイズの決定（GPU OOM回避のため小規模テスト実行）
- [ ] 学習率の設定確認
- [ ] `scripts/run_experiment_80sent.sh`の作成
- [ ] `scripts/run_experiment_4sent_37phonemes.sh`の作成
- [ ] `scripts/run_experiment_4sent_random.sh`の作成
- [ ] `scripts/run_experiment_10sent_top.sh`の作成
- [ ] E1（80文）のfine-tuning実行
- [ ] E2（37音素4文）のfine-tuning実行
- [ ] E3（ランダム4文）のfine-tuning実行
- [ ] E4（上位10文）のfine-tuning実行
- [ ] 各条件の学習ログ確認（損失の推移、収束状況）
- [ ] チェックポイントの保存確認

#### 完了条件
- 4条件すべてでfine-tuningが完了し、チェックポイントが保存されている
- 学習ログに異常（NaN、発散等）がない
- 各条件の学習時間が記録されている
- チェックポイントからモデルを読み込んで推論可能

---

### [Phase 5] 音声合成

#### 目的
各条件でfine-tuningしたモデルを使用し、テスト文から音声を合成する。

#### 前提
- **入力**: テストセットのテキスト（10-20文）
- **モデル**: Phase 4で保存した各条件のチェックポイント
- **出力**: 合成音声ファイル（WAV形式）

#### タスク
- [ ] `src/synthesize.py`の作成（音声合成スクリプト）
- [ ] テストセットのテキスト読み込み
- [ ] 各条件のチェックポイントからモデル読み込み
- [ ] テキストから音素列への変換
- [ ] 音声合成の実行（各条件×各テスト文）
- [ ] 合成音声の保存（`outputs/audio/<condition>/<sentence_id>.wav`）
- [ ] 合成音声の品質確認（聞き取り、異常音の有無）
- [ ] 合成ログの出力（処理時間、エラー文の有無）

#### 完了条件
- 4条件×テスト文数の合成音声ファイルが`outputs/audio/`に保存されている
- すべての合成音声が正常に生成されている（ファイルサイズ、再生可能）
- 合成音声のメタデータ（条件、文ID）が記録されている

---

### [Phase 6] 客観評価

#### 目的
合成音声と自然音声を比較し、MCD、log-F0 RMSE、CERを算出する。

#### 前提
- **入力**: 合成音声（Phase 5の出力）と自然音声（テストセットの元音声）
- **評価指標**: MCD (dB), log-F0 RMSE, CER
- **評価ツール**: ESPnet2評価スクリプト、ASR（Whisper/ESPnet2-ASR）

#### タスク
- [ ] `src/evaluate.py`の作成（客観評価スクリプト）
- [ ] MCD算出スクリプトの実装（またはESPnet2の`evaluate_mcd.py`を利用）
- [ ] log-F0 RMSE算出スクリプトの実装（またはESPnet2の`evaluate_f0.py`を利用）
- [ ] CER算出スクリプトの実装（ASR経由、WhisperまたはESPnet2-ASR）
- [ ] 評価スクリプトの動作確認（1サンプルでの手動計算と比較）
- [ ] 全条件×全テスト文の評価実行
- [ ] 評価結果の保存（`results/evaluation_results.json`）
- [ ] 各条件の平均値・標準偏差の計算
- [ ] `src/evaluate_all_conditions.py`の作成（一括評価スクリプト）
- [ ] 評価結果のCSV出力（条件別、指標別）

#### 完了条件
- 4条件すべてでMCD、log-F0 RMSE、CERが算出されている
- 評価結果がJSON/CSV形式で保存されている
- 各条件の平均値・標準偏差が計算されている
- 評価スクリプトが再現可能（同じ入力で同じ結果）

---

### [Phase 7] 結果可視化・分析

#### 目的
評価指標を比較図表にまとめ、音素カバレッジと品質の関係を分析・ドキュメント化する。

#### 前提
- **入力**: Phase 6の評価結果（JSON/CSV）
- **可視化ツール**: matplotlib, seaborn
- **出力**: 図表（PNG）、分析レポート（Markdown）

#### タスク
- [ ] `src/visualize.py`の作成（可視化スクリプト）
- [ ] 評価結果データの読み込み
- [ ] 条件別のMCD比較棒グラフ作成
- [ ] 条件別のlog-F0 RMSE比較棒グラフ作成
- [ ] 条件別のCER比較棒グラフ作成
- [ ] 音素カバレッジ vs 品質指標の散布図作成
- [ ] データ量（文数）vs 品質指標の関係図作成
- [ ] 図表の保存（`outputs/figures/`）
- [ ] `docs/results.md`の作成（実験結果レポート）
- [ ] 統計分析の実施（条件間の有意差検定等、可能な範囲で）
- [ ] 考察の記述（音素カバレッジと品質の関係、データ量と品質の関係）
- [ ] 最小限コーパス設計指針の整理

#### 完了条件
- 評価指標の比較図表（棒グラフ、散布図等）が`outputs/figures/`に保存されている
- `docs/results.md`に実験結果と考察が記載されている
- 音素カバレッジと品質の関係が定量的に示されている
- 今後のコーパス設計指針がまとめられている

---

## 3. 実験プラン（E1-E4）

### E1: 80文コーパス

#### 変更点
- 100文を8:2で分割した学習用80文を使用
- データ量が最大

#### 期待される結果
- 4条件中で最も高い品質（MCD低、F0 RMSE低、CER低）
- ベースラインとして機能

#### 採用基準
- 学習が正常に収束し、合成音声が生成可能
- 評価指標が算出可能

---

### E2: 37音素4文コーパス

#### 変更点
- 37音素を全てカバーする4文のみを使用
- データ量が最小だが音素カバレッジは最大

#### 期待される結果
- 80文より品質は低いが、ランダム4文よりは高い
- 音素カバレッジの重要性を示す

#### 採用基準
- 全37音素をカバーしていることを確認
- 学習が正常に収束（過学習の可能性あり）
- 合成音声が生成可能

---

### E3: ランダム4文コーパス

#### 変更点
- ランダムに選んだ4文を使用（対照群）
- 音素カバレッジは低い可能性が高い

#### 期待される結果
- 4条件中で最も低い品質（MCD高、F0 RMSE高、CER高）
- 音素カバレッジの重要性を対照的に示す

#### 採用基準
- ランダムシードを固定して再現可能
- 含有音素数を計測・記録
- 学習が正常に収束（品質は低い可能性）

---

### E4: 上位10文コーパス

#### 変更点
- 音素特徴量（ユニーク音素数 + レア音素数）上位10文を使用
- データ量と情報量のバランスを取る

#### 期待される結果
- 80文よりは低いが、4文よりは高い品質
- 情報量に基づく選定の有効性を示す

#### 採用基準
- 音素特徴量スコアリングが正しく実装されている
- 上位10文が選定されている
- 学習が正常に収束

---

## 4. リスク管理

### Phase 1のリスク
| リスク | 影響度 | 対応方針 |
|--------|--------|----------|
| ESPnet2環境構築失敗 | 高 | StyleTTS2へ早期切り替え、Docker環境も検討 |
| GPU認識不可 | 高 | CUDAドライバ確認、PyTorch再インストール |
| JVSデータ取得不可 | 高 | 代替データソースの検討、手動ダウンロード |

### Phase 2のリスク
| リスク | 影響度 | 対応方針 |
|--------|--------|----------|
| 37音素カバー4文が存在しない | 中 | 貪欲法を再実行、5文に拡張も検討 |
| 音素解析エラー | 中 | pyopenjtalkの設定確認、エラー文の除外 |

### Phase 3のリスク
| リスク | 影響度 | 対応方針 |
|--------|--------|----------|
| データ形式変換エラー | 中 | ESPnet2公式ドキュメント確認、サンプルデータでテスト |
| 音声ファイル破損 | 低 | ファイル整合性チェック、破損ファイルの除外 |

### Phase 4のリスク
| リスク | 影響度 | 対応方針 |
|--------|--------|----------|
| GPU OOM | 中 | バッチサイズ削減、mixed precision (fp16)使用、gradient accumulation |
| 学習が収束しない | 中 | 学習率を1/10に下げる、ステップ数を増やす（期限内で調整） |
| Fine-tuning時間超過 | 高 | ステップ数削減、条件数削減（ランダム4文を除外） |

### Phase 5のリスク
| リスク | 影響度 | 対応方針 |
|--------|--------|----------|
| 合成音声が生成されない | 高 | チェックポイント確認、モデル読み込み確認、エラーログ確認 |
| 合成音声の品質が極端に低い | 中 | ハイパーパラメータ調整、事前学習モデル変更 |

### Phase 6のリスク
| リスク | 影響度 | 対応方針 |
|--------|--------|----------|
| 評価指標の計算エラー | 中 | 手動で1サンプル計算して検証、ESPnet2公式評価スクリプトと比較 |
| ASR（CER算出）の精度不足 | 低 | WhisperとESPnet2-ASRの両方で試す、手動確認も実施 |

### Phase 7のリスク
| リスク | 影響度 | 対応方針 |
|--------|--------|----------|
| 統計分析の時間不足 | 低 | 基本統計のみ、図表は最小限に |

### 期限リスクへの対応
- **1/18時点で進捗50%未満の場合**: 条件を4→3に削減（ランダム4文を除外）
- **1/20時点で評価未完了の場合**: MCD/F0のみに絞る（CERは削除）
- **1/21時点で分析未完了の場合**: 基本統計のみ、図表は最小限に

---

## 5. タスク優先度と実装順序

### 最優先（MVP必須）
1. Phase 1: 環境構築・データ準備
2. Phase 2: 音素分析・コーパス選定
3. Phase 3: データ前処理
4. Phase 4: Fine-tuning実験（最低2条件: E1, E2）
5. Phase 5: 音声合成
6. Phase 6: 客観評価（最低MCD, F0 RMSE）
7. Phase 7: 結果可視化・分析（最小限）

### 次優先（品質向上）
- Phase 4: 全4条件のfine-tuning
- Phase 6: CER評価の追加
- Phase 7: 詳細な統計分析

### 低優先（時間があれば）
- 追加の可視化
- 詳細な考察の記述

---

## 6. チェックポイント（マイルストーン）

### 1/16終了時点
- [ ] Phase 1完了
- [ ] Phase 2完了

### 1/18終了時点
- [ ] Phase 3完了
- [ ] Phase 4の最低2条件（E1, E2）完了

### 1/20終了時点
- [ ] Phase 4全条件完了
- [ ] Phase 5完了
- [ ] Phase 6完了（最低MCD, F0 RMSE）

### 1/22終了時点
- [ ] Phase 7完了
- [ ] 全ドキュメント整備完了

---

## 変更履歴

| Date | Version | Changes |
|------|---------|---------|
| 2026-01-15 | 1.0 | 初版作成 |
